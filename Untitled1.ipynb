{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-3-1a11e5adf3ff>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-1a11e5adf3ff>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    （1）mnist_test_conv.py代碼如下\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "（1）mnist_test_conv.py代碼如下\n",
    "#! /usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    " \n",
    "'''\n",
    "構造一個卷積神經網絡來訓練mnist：\n",
    "輸入層： 784個輸入節點\n",
    "兩個卷積層（每個都具有一個卷積和Pooling操作）：\n",
    "\t卷積操作：步長為1，邊距為0，filter: 5x5\n",
    "\tPooling(池化): 採用maxpooing, 2x2矩陣作為模板\n",
    "輸出層： 10個輸出節點\n",
    "'''\n",
    " \n",
    "import input_data\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import struct\n",
    " \n",
    "#定義初始化操作\n",
    "def weight_variable(shape):\n",
    "\tinit = tf.truncated_normal(shape, stddev=0.1)\n",
    "\treturn tf.Variable(init)\n",
    " \n",
    "def bias_variable(shape):\n",
    "\tinit = tf.constant(0.1, shape = shape)\n",
    "\treturn tf.Variable(init)\n",
    " \n",
    "#定義卷積和池化操作\n",
    "'''\n",
    "卷積後的圖像高寬計算公式： W2 = (W1 - Fw + 2P) / S + 1\n",
    "其中：Fw為filter的寬，P為周圍補0的圈數，S是步幅\n",
    "'''\n",
    "def conv2d(x, W):\n",
    "\treturn tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    " \n",
    "def max_pool_2x2(x):\n",
    "\treturn tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    " \n",
    "'''\n",
    "(1) 數據加載\n",
    "'''\n",
    "#mnist數據路徑\n",
    "mnist_data_path = \"/home/fcx/share/test/deeplearning/mnist/mnist_data\"\n",
    "#加載mnist數據\n",
    "mnist_data = input_data.read_data_sets(mnist_data_path, one_hot=True)\n",
    " \n",
    "'''\n",
    "(2) 輸入層，輸入張量x定義\n",
    "'''\n",
    "#神經網絡輸入層變量x定義\n",
    "with tf.name_scope('input_layer'):\n",
    "\tx = tf.placeholder(\"float\", [None, 784]) #可以存放n個784（28x28）的數組\n",
    " \n",
    "'''\n",
    "(3) 第一層卷積層\n",
    "'''\n",
    "with tf.name_scope('conv_layer_1'):\n",
    "\t#定義卷積操作的filter為5x5的矩陣，且輸出32個feature map, 輸入的圖片的通道數為1，因為是灰度圖像\n",
    "\tW_conv1 = weight_variable([5, 5, 1, 32])\n",
    "\tb_conv1 = bias_variable([32])\n",
    "\t#先將圖像數據進行維度的變化\n",
    "\tx_image = tf.reshape(x, [-1, 28, 28, 1]) # 28x28的單通道圖像\n",
    "\t#卷積操作\n",
    "\t'''\n",
    "\t輸出h_conv1維度為：[-1, 28, 28, 32], 之所以還是28x28是因為參數padding='SAME'\n",
    "\t如果採用padding='VALID'則輸出為24x24, 用公式W2 = (W1 - Fw + 2P) / S + 1，24 = (28 - 5 + 2 * 0) / 1 + 1\n",
    "\t'''\n",
    "\th_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\t#將卷積完的結果進行pooling操作\n",
    "\t#輸出h_pool1維度為：[-1, 14, 14, 32]\n",
    "\th_pool1 = max_pool_2x2(h_conv1)\n",
    " \n",
    "'''\n",
    "(3) 第二層卷積層\n",
    "'''\n",
    "with tf.name_scope('conv_layer_2'):\n",
    "\t#定義卷積操作的map為5x5的矩陣，且輸出64個feature map, 輸入的圖片的通道數為32\n",
    "\tW_conv2 = weight_variable([5, 5, 32, 64])\n",
    "\tb_conv2 = bias_variable([64])\n",
    "\t#卷積操作\n",
    "\t#輸出h_conv2維度為：[-1, 14, 14, 64]\n",
    "\th_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\t#將卷積完的結果進行pooling操作\n",
    "\t#輸出h_pool2維度為：[-1, 7, 7, 64]\n",
    "\th_pool2 = max_pool_2x2(h_conv2)\n",
    "#到此為止一張28x28的圖片就變成了64個7x7的矩陣\n",
    " \n",
    "'''\n",
    "(4) 全連接層定義（full connection layer）\n",
    "'''\n",
    "with tf.name_scope('full_connection_layer'):\n",
    "\t#卷積層2輸出作為輸入和隱藏層之間的權重矩陣W_fc1,偏置項b_fc1初始化\n",
    "\t#定義隱藏層的節點數\n",
    "\thide_neurons = 1024\n",
    "\t#W_fc1 = weight_variable([7*7*64, hide_neurons])\n",
    "\t#計算卷積層2輸出的tensor，變化為一維的大小\n",
    "\th_pool2_shape = h_pool2.get_shape().as_list() #得到一個列表[batch, hight, width, channels]\n",
    "\tfc_input_size = h_pool2_shape[1] * h_pool2_shape[2] * h_pool2_shape[3] # hight * width * channels\n",
    "\tW_fc1 = weight_variable([fc_input_size, hide_neurons])\n",
    "\tb_fc1 = bias_variable([hide_neurons])\n",
    "\t#將卷積層2的輸出張量扁平化作為全連接神經網絡的輸入\n",
    "\tfc_x = tf.reshape(h_pool2, [-1, fc_input_size])\n",
    "\t#全連接層中隱藏層的輸出\n",
    "\tfc_h = tf.nn.relu(tf.matmul(fc_x, W_fc1) + b_fc1)\n",
    " \n",
    "\t#為了減少過擬合，在隱藏層和輸出層之間加人dropout操作。\n",
    "\t#用來代表一個神經元的輸出在dropout中保存不變的概率。\n",
    "\t#在訓練的過程啟動dropout，在測試過程中關閉dropout\n",
    "\tkeep_prob = tf.placeholder(\"float\")\n",
    "\tdrop_fc_h = tf.nn.dropout(fc_h, keep_prob)\n",
    " \n",
    "\t#隱藏層到輸出層\n",
    "\tW_fc2 = weight_variable([hide_neurons, 10])\n",
    "\tb_fc2 = bias_variable([10])\n",
    "\ty = tf.nn.softmax(tf.matmul(drop_fc_h, W_fc2) + b_fc2)\n",
    " \n",
    "'''\n",
    "(5) 設置訓練方法，及其他超參數\n",
    "'''\n",
    "#設置期待輸出值\n",
    "y_ = tf.placeholder(\"float\", [None, 10])\n",
    "#設置損失函數為交叉嫡函數(negative log-likelihood函數)\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "#單步訓練操作,使用梯度下降算法,學習速率：0.01，損失函數：cross_entropy\n",
    "#train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "#使用更複雜的ADAM優化器來做梯度最速下降\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "#初始化\n",
    "init = tf.initialize_all_variables()\n",
    " \n",
    "#定義saver用來保存訓練好的模型參數\n",
    "saver = tf.train.Saver()\n",
    " \n",
    "#定義檢測正確率的方法\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)) #用向量y和y_中的最大值進行比較\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) #對正確率求均值\n",
    " \n",
    "def train_and_test():\n",
    "\t#建立會話\n",
    "\twith tf.Session() as sess:\n",
    "\t\t'''\n",
    "\t\t(6) 開始訓練\n",
    "\t\t'''\n",
    "\t\t#執行初始化\n",
    "\t\tsess.run(init)\n",
    " \n",
    "\t\t#開始訓練10000次\n",
    "\t\tfor i in range(10000):\n",
    "\t\t\ttran_sets_batch = mnist_data.train.next_batch(100) #每次取得100個樣本\n",
    "\t\t\tsess.run(train_step, feed_dict={x: tran_sets_batch[0], y_: tran_sets_batch[1], keep_prob: 0.5})\n",
    " \n",
    "\t\t\t#每100次訓練完都檢測下測試的正確率,只從5000個測試樣本中簡單抽取100個進行測試\n",
    "\t\t\tif i % 100 == 0:\n",
    "\t\t\t\tvalidation_sets_batch = mnist_data.validation.next_batch(100)\n",
    "\t\t\t\tcur_rate = sess.run(accuracy, feed_dict = {x: validation_sets_batch[0], y_: validation_sets_batch[1], keep_prob: 1})\n",
    "\t\t\t\tprint('epoch %d accuracy: %s' % (i, cur_rate))\n",
    " \n",
    "\t\t#保存訓練後的模型參數\n",
    "\t\tsaver.save(sess, './save_model_data_conv/model.ckpt')\n",
    " \n",
    "\t\t'''\n",
    "\t\t(7) 用訓練好的模型測試10000個樣本最終的準確度\n",
    "\t\t'''\n",
    "\t\t#這樣會報Resource Exhausted 顯存資源不足的錯誤\n",
    "\t\t#rate = sess.run(accuracy, feed_dict = {x: mnist_data.test.images, y_: mnist_data.test.labels, keep_prob: 1})\n",
    "\t\t#print('Mean Accuracy is %s' % rate)\n",
    " \n",
    "\t\t#只好多次加載統計結果\n",
    "\t\tsum_rate = 0\n",
    "\t\tfor i in range(100):\n",
    "\t\t\ttest_sets_batch = mnist_data.test.next_batch(100)\n",
    "\t\t\tepoch_rate = sess.run(accuracy, feed_dict = {x: test_sets_batch[0], y_: test_sets_batch[1], keep_prob: 1})\n",
    "\t\t\tsum_rate = sum_rate + epoch_rate\n",
    "\t\tprint('Mean Accuracy is %s' % (sum_rate / 100))\n",
    " \n",
    " \n",
    "#檢驗是否是bmp圖片 54字節頭 + 數據部分\n",
    "def checkIsBmp(file):\n",
    "\twith open(file, 'rb') as f:\n",
    "\t\thead = struct.unpack('<ccIIIIIIHH', f.read(30)) #將讀取到的30個字節，轉換為指定數據類型的數字\n",
    "\t\t#print(head)\n",
    "\t\tif head[0] == b'B' and head[1] == b'M':\n",
    "\t\t\t#print('%s 總大小：%d, 圖片尺寸：%d X %d, 顏色數：%d' % (file, head[2], head[6], head[7], head[9]))\n",
    "\t\t\treturn True, head[2], head[9] #返回圖片總大小，以及一個像素用多少bit表示\n",
    "\t\telse:\n",
    "\t\t\t#print('%s 不是Bmp圖片' % file)\n",
    "\t\t\treturn False, 0, 0\n",
    " \n",
    "def test_my_data():\n",
    "\twith tf.Session() as sess:\n",
    "\t\t''' 恢復訓練好的數據 '''\n",
    "\t\tmodel_data = tf.train.latest_checkpoint('./save_model_data_conv/')\n",
    "\t\tsaver.restore(sess, model_data)\n",
    "\t\t'''\n",
    "\t\t#只好多次加載統計結果\n",
    "\t\tsum_rate = 0\n",
    "\t\tfor i in range(100):\n",
    "\t\t\ttest_sets_batch = mnist_data.test.next_batch(100)\n",
    "\t\t\tepoch_rate = sess.run(accuracy, feed_dict = {x: test_sets_batch[0], y_: test_sets_batch[1], keep_prob: 1})\n",
    "\t\t\tsum_rate = sum_rate + epoch_rate\n",
    "\t\tprint('The Accuracy tested by MNIST Test samples is: %s' % (sum_rate / 100))\n",
    "\t\t'''\n",
    " \n",
    "\t\tprint('Start recognizing my image:')\n",
    "\t\tmy_data_path = './my_test_images/'\n",
    "\t\tprint(os.listdir(my_data_path))\n",
    "\t\tfor image_name in os.listdir(my_data_path):\n",
    "\t\t\timage_path = os.path.join(my_data_path, image_name)\n",
    "\t\t\tret, file_size, bitCnt_per_pix = checkIsBmp(image_path)\n",
    "\t\t\tif ret == True:\n",
    "\t\t\t\twith open(image_path, 'rb') as f:\n",
    "\t\t\t\t\tformate = '%dB' % file_size\n",
    "\t\t\t\t\tdata_bytes = struct.unpack(formate, f.read(file_size)) #按unsigned char 讀取文件\n",
    "\t\t\t\t\timage_np = np.zeros((1, 784))\n",
    "\t\t\t\t\t#print(image_np.shape)\n",
    "\t\t\t\t\tstep = bitCnt_per_pix / 8\n",
    "\t\t\t\t\tstart_pos = 54  #54字節的頭信息\n",
    "\t\t\t\t\tif bitCnt_per_pix == 8: #如果是8位深度的bmp圖片，有調色板\n",
    "\t\t\t\t\t\tstart_pos = start_pos + 1024 #1024字節的調色板\n",
    "\t\t\n",
    "\t\t\t\t\tfor i in range(784):\n",
    "\t\t\t\t\t\tpos = start_pos + i * step\n",
    "\t\t\t\t\t\tif bitCnt_per_pix == 8:\n",
    "\t\t\t\t\t\t\tpix_value = data_bytes[pos]\n",
    "\t\t\t\t\t\telif bitCnt_per_pix == 24:\n",
    "\t\t\t\t\t\t\t#gray = red * 0.299 + green * 0.587 + blue * 0.114 RGB和灰度圖的轉換\n",
    "\t\t\t\t\t\t\tpix_value = data_bytes[pos] * 0.299 + data_bytes[pos+1] * 0.587 + data_bytes[pos+2] * 0.114\n",
    "\t\t\t\t\t\timage_np[0][i] = pix_value / 255.0 # [0..255] --> [0.0... 1.0]\n",
    "\t\t\t\t\t\t#print(image_np[0][i])\n",
    "\t\t\t\t\tmax_idx, out = sess.run([tf.argmax(y, 1), y], feed_dict = {x: image_np, keep_prob: 1})\n",
    "\t\t\t\t\tprint('####The image name: %s, predict number is: %d' % (image_name, max_idx))\n",
    " \n",
    "def main(_):\n",
    "\tif ARGS.test:\n",
    "\t\tprint('************** Predict by Neural network ***************')\n",
    "\t\ttest_my_data()\n",
    "\telse:\n",
    "\t\tprint('************** Train and Test accuracy of Neural network ***************')\n",
    "\t\ttrain_and_test()\n",
    " \n",
    "if __name__ == '__main__':\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\tparser.add_argument(\n",
    "\t\t'-t',\n",
    "\t\t'--test',\n",
    "\t\tdefault = False,\n",
    "\t\taction = 'store_true',\n",
    "\t\thelp = 'Excute training network or testing network.'\n",
    "\t\t)\n",
    "  \n",
    "\tARGS = parser.parse_args()\n",
    "\tprint('ARGS: %s' % ARGS)\n",
    "\ttf.app.run()\n",
    " \n",
    "'''\n",
    "(1)tf.argmax(input, axis=None, name=None, dimension=None)\n",
    "此函數是對矩陣按行或列計算最大值\n",
    "參數\n",
    "    input：輸入Tensor\n",
    "    axis：0表示按列，1表示按行\n",
    "    name：名稱\n",
    "    dimension：和axis功能一樣，默認axis取值優先。新加的字段\n",
    "返回：Tensor 行或列的最大值下標向量\n",
    "(2)tf.equal(a, b)\n",
    "此函數比較等維度的a, b矩陣相應位置的元素是否相等，相等返回True,否則為False\n",
    "返回：同維度的矩陣，元素值為True或False\n",
    "(3)tf.cast(x, dtype, name=None)\n",
    "將x的數據格式轉化成dtype.例如，原來x的數據格式是bool，\n",
    "那麼將其轉化成float以後，就能夠將其轉化成0和1的序列。反之也可以\n",
    "(4)tf.reduce_max(input_tensor, reduction_indices=None, keep_dims=False, name=None)\n",
    " 功能：求某維度的最大值\n",
    "(5)tf.reduce_mean(input_tensor, reduction_indices=None, keep_dims=False, name=None)\n",
    "功能：求某維度的均值\n",
    "參數1--input_tensor:待求值的tensor。\n",
    "參數2--reduction_indices:在哪一維上求解。0表示按列，1表示按行\n",
    "參數（3）（4）可忽略\n",
    "例：x = [ 1, 2\n",
    "\t\t  3, 4]\n",
    "x = tf.constant([[1,2],[3,4]], \"float\")\n",
    "tf.reduce_mean(x) = 2.5\n",
    "tf.reduce_mean(x, 0) = [2, 3]\n",
    "tf.reduce_mean(x, 1) = [1.5, 3.5]\n",
    "(6)tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "從截斷的正態分佈中輸出隨機值\n",
    "    shape: 輸出的張量的維度尺寸。\n",
    "    mean: 正態分佈的均值。\n",
    "    stddev: 正態分佈的標準差。\n",
    "    dtype: 輸出的類型。\n",
    "    seed: 一個整數，當設置之後，每次生成的隨機數都一樣。\n",
    "    name: 操作的名字。\n",
    "（7）tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "從標準正態分佈中輸出隨機值\n",
    "(8) tf.nn.conv2d(input, filter, strides, padding, \n",
    "\t\t\t\t use_cudnn_on_gpu=None, data_format=None, name=None)\n",
    "在給定的4D input與 filter下計算2D卷積\n",
    "\t1，輸入shape為 [batch, height, width, in_channels]: batch為圖片數量，in_channels為圖片通道數\n",
    "\t2，第二個參數filter：相當於CNN中的卷積核，它要求是一個Tensor，具有[filter_height, filter_width, \n",
    "\t\tin_channels, out_channels]這樣的shape，具體含義是[卷積核的高度，卷積核的寬度，圖像通道數，\n",
    "\t\t卷積核個數]，要求類型與參數input相同，有一個地方需要注意，第三維in_channels，就是參數input\n",
    "\t\t的第四維\n",
    "\t3，第三個參數strides：卷積時在圖像每一維的步長，這是一個一維的向量，長度4\n",
    "\t4，第四個參數padding：string類型的量，只能是\"SAME\",\"VALID\"其中之一，這個值決定了不同的卷積方式（後面會介紹）\n",
    "\t5，第五個參數：use_cudnn_on_gpu:bool類型，是否使用cudnn加速，默認為true\n",
    "\t結果返回一個Tensor，這個輸出，就是我們常說的feature map，shape仍然是[batch, height, width, channels]這種形式。\n",
    "(9)tf.nn.max_pool(value, ksize, strides, padding, name=None)\n",
    "參數是四個，和卷積很類似：\n",
    "第一個參數value：需要池化的輸入，一般池化層接在卷積層後面，所以輸入通常是feature map，\n",
    "\t依然是[batch, height, width, channels]這樣的shape\n",
    "第二個參數ksize：池化窗口的大小，取一個四維向量，一般是[1, height, width, 1]，因為我們\n",
    "\t不想在batch和channels上做池化，所以這兩個維度設為了1\n",
    "第三個參數strides：和卷積類似，窗口在每一個維度上滑動的步長，一般也是[1, stride,stride, 1]\n",
    "第四個參數padding：和卷積類似，可以取'VALID' 或者'SAME'\n",
    "返回一個Tensor，類型不變，shape仍然是[batch, height, width, channels]這種形式\n",
    "(10) tf.reshape(tensor, shape, name=None)\n",
    "函數的作用是將tensor變換為參數shape的形式。\n",
    "其中shape為一個列表形式，特殊的一點是列表中可以存在-1。-1代表的含義是不用我們自己指定這一維的大小，\n",
    "函數會自動計算，但列表中只能存在一個-1。（當然如果存在多個-1，就是一個存在多解的方程了）\n",
    "(11)tf.nn.dropout(x, keep_prob, noise_shape=None, seed=None,name=None) \n",
    "為了減少過擬合，隨機扔掉一些神經元，這些神經元不參與權重的更新和運算\n",
    "參數：\n",
    "\tx            :  輸入tensor\n",
    "\tkeep_prob    :  float類型，每個元素被保留下來的概率\n",
    "\tnoise_shape  : 一個1維的int32張量，代表了隨機產生“保留/丟棄”標誌的shape。\n",
    "\tseed         : 整形變量，隨機數種子。\n",
    "\tname         : 名字，沒啥用。 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-06b29a23c178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6114373f6809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"TensorFlow version: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print (\"TensorFlow version: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

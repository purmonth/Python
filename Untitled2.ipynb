{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-2-26c38c3f7b6d>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-26c38c3f7b6d>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    x = tf.placeholder(tf.float32, [None, 784])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "\n",
    "import tensorflow as tf \n",
    " \n",
    " x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    " W = tf.Variable(tf.zeros([784, 10]))\n",
    " b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "\n",
    " y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    " y_ = tf.placeholder(tf.float32, [None, 10])\n",
    " cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    " \n",
    "\n",
    "\n",
    "\n",
    " learning_rate = 0.05\n",
    " train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    " sess = tf.Session()\n",
    " tf.global_variables_initializer().run()\n",
    " for _ in range(1000):\n",
    " \tbatch_xs, batch_ys = mnist.train.next_batch(100)\n",
    " \tsess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    " correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    " accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    " print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-292b9248f01e>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./MNIST/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'matul'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-292b9248f01e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mtrain_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-292b9248f01e>\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# output of NN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-292b9248f01e>\u001b[0m in \u001b[0;36mbuild_nn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mhidden_layer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mhidden_layer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moutput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-292b9248f01e>\u001b[0m in \u001b[0;36madd_layer\u001b[0;34m(input_data, input_num, output_num, activation_function)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m#activation? output = activation_function(output) : output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mactivation_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dw_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accessing local variables before they are created.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     if (self._dw_warning_count < _PER_MODULE_WARNING_LIMIT and\n\u001b[1;32m    108\u001b[0m         name not in self._dw_deprecated_printed):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'matul'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('./MNIST', one_hot=True)\n",
    "\n",
    "#input_layer\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None,784], name='x')\n",
    "#labels\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None,10], name='y')\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "def add_layer(input_data, input_num, output_num, activation_function=None):\n",
    "\t#output = input_data * weight + bias\n",
    "\tw = tf.Variable(initial_value = tf.random_normal(shape=[input_num, output_num]))\n",
    "\tb = tf.Variable(initial_value = tf.random_normal(shape=[1, output_num]))\n",
    "\toutput = tf.add(tf.matul(input_data, w), b)\n",
    "\t#activation? output = activation_function(output) : output\n",
    "\tif activation_function:\n",
    "\t\toutput = activation_function(output)\n",
    "\treturn output\n",
    "\t\n",
    "\n",
    "def build_nn(data):\n",
    "\thidden_layer1 = add_layer(data, 784, 100, activation_function=tf.nn.sigmoid)\n",
    "\thidden_layer2 = add_layer(hidden_layer1, 100, 50, activation_function=tf.nn.sigmoid)\n",
    "\toutput_layer = add_layer(hidden_layer2, 50, 10)\n",
    "\treturn output_layer\n",
    "\n",
    "def train_nn(data):\n",
    "\t# output of NN\n",
    "\toutput = build_nn(data)\n",
    "\n",
    "\tloss = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output)\n",
    "\toptimizer = tf.train.GradientDescentOptimizer(learning_rate=1).minimize(loss)\n",
    "\n",
    "\n",
    "\twith tf.Session() as sess:\n",
    "\t\tsess.run(tf.global_variables_initializer())\n",
    "\t\tfor _ in range(50):\n",
    "\t\t\tepoch_cost = 0\n",
    "\t\t\tfor _ in range(int(mnist.train.num_wxamples / batch_size)):\n",
    "\t\t\t\tx_data, y_data = mnist.train.next_batch(batch_size)\n",
    "\t\t\t\tcost, _ = sess.run([loss, optimizer], feed_dict={x: x_data, y: y_data})\n",
    "\t\t\t\tepoch_cost += cost\n",
    "\t\t\tprint('Epoch', i, ': ', epoch_cost)\n",
    "\n",
    "\n",
    "train_nn(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-32406192f58c>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-32406192f58c>:35: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch 0 :  96.40404069423676\n",
      "Epoch 1 :  48.2375248670578\n",
      "Epoch 2 :  38.19425868988037\n",
      "Epoch 3 :  33.068891763687134\n",
      "Epoch 4 :  29.779543787240982\n",
      "Epoch 5 :  27.41325905919075\n",
      "Epoch 6 :  25.566686928272247\n",
      "Epoch 7 :  24.134378403425217\n",
      "Epoch 8 :  22.935086101293564\n",
      "Epoch 9 :  21.866574108600616\n",
      "Epoch 10 :  20.972550481557846\n",
      "Epoch 11 :  20.188227951526642\n",
      "Epoch 12 :  19.488261610269547\n",
      "Epoch 13 :  18.80759361386299\n",
      "Epoch 14 :  18.267844915390015\n",
      "Epoch 15 :  17.720670610666275\n",
      "Epoch 16 :  17.240690499544144\n",
      "Epoch 17 :  16.76515792310238\n",
      "Epoch 18 :  16.3525477796793\n",
      "Epoch 19 :  15.948302313685417\n",
      "Epoch 20 :  15.58385719358921\n",
      "Epoch 21 :  15.260212168097496\n",
      "Epoch 22 :  14.899977758526802\n",
      "Epoch 23 :  14.608863070607185\n",
      "Epoch 24 :  14.30908551812172\n",
      "Epoch 25 :  14.054111734032631\n",
      "Epoch 26 :  13.79406002163887\n",
      "Epoch 27 :  13.519230127334595\n",
      "Epoch 28 :  13.283317267894745\n",
      "Epoch 29 :  13.043060645461082\n",
      "Epoch 30 :  12.841736242175102\n",
      "Epoch 31 :  12.609840884804726\n",
      "Epoch 32 :  12.421912208199501\n",
      "Epoch 33 :  12.215822696685791\n",
      "Epoch 34 :  12.038092762231827\n",
      "Epoch 35 :  11.849869012832642\n",
      "Epoch 36 :  11.67348226904869\n",
      "Epoch 37 :  11.514404386281967\n",
      "Epoch 38 :  11.33833034336567\n",
      "Epoch 39 :  11.18427175283432\n",
      "Epoch 40 :  11.021166861057281\n",
      "Epoch 41 :  10.881200149655342\n",
      "Epoch 42 :  10.734985455870628\n",
      "Epoch 43 :  10.594377994537354\n",
      "Epoch 44 :  10.453529819846153\n",
      "Epoch 45 :  10.323534101247787\n",
      "Epoch 46 :  10.20036207139492\n",
      "Epoch 47 :  10.083197131752968\n",
      "Epoch 48 :  9.961227491497993\n",
      "Epoch 49 :  9.82646258175373\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'input' has DataType bool not in list of allowed values: float32, float64, int32, uint8, int16, int8, complex64, int64, qint8, quint8, qint32, bfloat16, uint16, complex128, float16, uint32, uint64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-32406192f58c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mtrain_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-32406192f58c>\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     46\u001b[0m                                 \u001b[0mepoch_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_mean_v1\u001b[0;34m(input_tensor, axis, keepdims, name, reduction_indices, keep_dims)\u001b[0m\n\u001b[1;32m   1704\u001b[0m   keepdims = deprecation.deprecated_argument_lookup(\"keepdims\", keepdims,\n\u001b[1;32m   1705\u001b[0m                                                     \"keep_dims\", keep_dims)\n\u001b[0;32m-> 1706\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_mean\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   1762\u001b[0m       gen_math_ops.mean(\n\u001b[1;32m   1763\u001b[0m           \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m           name=name))\n\u001b[0m\u001b[1;32m   1765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m   6178\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   6179\u001b[0m         \u001b[0;34m\"Mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6180\u001b[0;31m                 name=name)\n\u001b[0m\u001b[1;32m   6181\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6182\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    624\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[1;32m    625\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m                                        param_name=input_name)\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[0;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0;34m\"allowed values: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[0;32m---> 60\u001b[0;31m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Value passed to parameter 'input' has DataType bool not in list of allowed values: float32, float64, int32, uint8, int16, int8, complex64, int64, qint8, quint8, qint32, bfloat16, uint16, complex128, float16, uint32, uint64"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('./MNIST', one_hot=True)\n",
    "\n",
    "#input_layer\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None,784], name='x')\n",
    "#labels\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None,10], name='y')\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "def add_layer(input_data, input_num, output_num, activation_function=None):\n",
    "\t#output = input_data * weight + bias\n",
    "\tw = tf.Variable(initial_value=tf.random_normal(shape=[input_num, output_num]))\n",
    "\tb = tf.Variable(initial_value=tf.random_normal(shape=[1, output_num]))\n",
    "\toutput = tf.add(tf.matmul(input_data, w), b)\n",
    "\t#activation? output = activation_function(output) : output\n",
    "\tif activation_function:\n",
    "\t\toutput = activation_function(output)\n",
    "\treturn output\n",
    "\t\n",
    "\n",
    "def build_nn(data):\n",
    "\thidden_layer1 = add_layer(data, 784, 100, activation_function=tf.nn.sigmoid)\n",
    "\thidden_layer2 = add_layer(hidden_layer1, 100, 50, activation_function=tf.nn.sigmoid)\n",
    "\toutput_layer = add_layer(hidden_layer2, 50, 10)\n",
    "\treturn output_layer\n",
    "\n",
    "def train_nn(data):\n",
    "\t# output of NN\n",
    "\toutput = build_nn(data)\n",
    "\n",
    "\tloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output))\n",
    "\toptimizer = tf.train.GradientDescentOptimizer(learning_rate=1).minimize(loss)\n",
    "\n",
    "\n",
    "\twith tf.Session() as sess:\n",
    "\t\tsess.run(tf.global_variables_initializer())\n",
    "\t\tfor i in range(50):\n",
    "\t\t\tepoch_cost = 0\n",
    "\t\t\tfor _ in range(int(mnist.train.num_examples / batch_size)):\n",
    "\t\t\t\tx_data, y_data = mnist.train.next_batch(batch_size)\n",
    "\t\t\t\tcost, _ = sess.run([loss, optimizer], feed_dict={x: x_data, y: y_data})\n",
    "\t\t\t\tepoch_cost += cost\n",
    "\t\t\tprint('Epoch', i, ': ', epoch_cost)\n",
    "\t\taccuracy = tf.reduce_mean(tf.equal(tf.argmax(y, 1), tf.argmax(output, 1)))\n",
    "\t\tacc = sess.run(accuracy, feed_dict={x: mnist.test.images, y:mnist.test.labels})\n",
    "\t\tprint(acc)\n",
    "\n",
    "\n",
    "train_nn(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Epoch 0 :  98.06475150585175\n",
      "Epoch 1 :  50.5432990193367\n",
      "Epoch 2 :  41.005087435245514\n",
      "Epoch 3 :  35.626270174980164\n",
      "Epoch 4 :  32.0650110244751\n",
      "Epoch 5 :  29.45045605301857\n",
      "Epoch 6 :  27.397424817085266\n",
      "Epoch 7 :  25.77886837720871\n",
      "Epoch 8 :  24.41167649626732\n",
      "Epoch 9 :  23.243982434272766\n",
      "Epoch 10 :  22.223884254693985\n",
      "Epoch 11 :  21.357547730207443\n",
      "Epoch 12 :  20.560326159000397\n",
      "Epoch 13 :  19.878439396619797\n",
      "Epoch 14 :  19.26376783847809\n",
      "Epoch 15 :  18.687265425920486\n",
      "Epoch 16 :  18.163066685199738\n",
      "Epoch 17 :  17.66855499148369\n",
      "Epoch 18 :  17.225654661655426\n",
      "Epoch 19 :  16.806100264191628\n",
      "Epoch 20 :  16.43321041762829\n",
      "Epoch 21 :  16.08352129161358\n",
      "Epoch 22 :  15.75071069598198\n",
      "Epoch 23 :  15.42913706600666\n",
      "Epoch 24 :  15.120894521474838\n",
      "Epoch 25 :  14.827313467860222\n",
      "Epoch 26 :  14.586428806185722\n",
      "Epoch 27 :  14.313869312405586\n",
      "Epoch 28 :  14.084264934062958\n",
      "Epoch 29 :  13.839930430054665\n",
      "Epoch 30 :  13.617720693349838\n",
      "Epoch 31 :  13.401629343628883\n",
      "Epoch 32 :  13.189913272857666\n",
      "Epoch 33 :  12.998442769050598\n",
      "Epoch 34 :  12.816014587879181\n",
      "Epoch 35 :  12.622123077511787\n",
      "Epoch 36 :  12.444811701774597\n",
      "Epoch 37 :  12.267277374863625\n",
      "Epoch 38 :  12.11037366092205\n",
      "Epoch 39 :  11.92981082201004\n",
      "Epoch 40 :  11.779417008161545\n",
      "Epoch 41 :  11.640798047184944\n",
      "Epoch 42 :  11.475484549999237\n",
      "Epoch 43 :  11.329922303557396\n",
      "Epoch 44 :  11.19733813405037\n",
      "Epoch 45 :  11.052842631936073\n",
      "Epoch 46 :  10.922329977154732\n",
      "Epoch 47 :  10.777287915349007\n",
      "Epoch 48 :  10.674185931682587\n",
      "Epoch 49 :  10.538464531302452\n",
      "0.9245\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('./MNIST', one_hot=True)\n",
    "\n",
    "#input_layer\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None,784], name='x')\n",
    "#labels\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None,10], name='y')\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "def add_layer(input_data, input_num, output_num, activation_function=None):\n",
    "\t#output = input_data * weight + bias\n",
    "\tw = tf.Variable(initial_value=tf.random_normal(shape=[input_num, output_num]))\n",
    "\tb = tf.Variable(initial_value=tf.random_normal(shape=[1, output_num]))\n",
    "\toutput = tf.add(tf.matmul(input_data, w), b)\n",
    "\t#activation? output = activation_function(output) : output\n",
    "\tif activation_function:\n",
    "\t\toutput = activation_function(output)\n",
    "\treturn output\n",
    "\t\n",
    "\n",
    "def build_nn(data):\n",
    "\thidden_layer1 = add_layer(data, 784, 100, activation_function=tf.nn.sigmoid)\n",
    "\thidden_layer2 = add_layer(hidden_layer1, 100, 50, activation_function=tf.nn.sigmoid)\n",
    "\toutput_layer = add_layer(hidden_layer2, 50, 10)\n",
    "\treturn output_layer\n",
    "\n",
    "def train_nn(data):\n",
    "\t# output of NN\n",
    "\toutput = build_nn(data)\n",
    "\n",
    "\tloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output))\n",
    "\toptimizer = tf.train.GradientDescentOptimizer(learning_rate=1).minimize(loss)\n",
    "\n",
    "\n",
    "\twith tf.Session() as sess:\n",
    "\t\tsess.run(tf.global_variables_initializer())\n",
    "\t\tfor i in range(50):\n",
    "\t\t\tepoch_cost = 0\n",
    "\t\t\tfor _ in range(int(mnist.train.num_examples / batch_size)):\n",
    "\t\t\t\tx_data, y_data = mnist.train.next_batch(batch_size)\n",
    "\t\t\t\tcost, _ = sess.run([loss, optimizer], feed_dict={x: x_data, y: y_data})\n",
    "\t\t\t\tepoch_cost += cost\n",
    "\t\t\tprint('Epoch', i, ': ', epoch_cost)\n",
    "\t\taccuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y, 1), tf.argmax(output, 1)), tf.float32)) \n",
    "\t\tacc = sess.run(accuracy, feed_dict={x: mnist.test.images, y:mnist.test.labels})\n",
    "\t\tprint(acc)\n",
    "\n",
    "\n",
    "train_nn(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

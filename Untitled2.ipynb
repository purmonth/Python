{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-2-26c38c3f7b6d>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-26c38c3f7b6d>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    x = tf.placeholder(tf.float32, [None, 784])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "\n",
    "import tensorflow as tf \n",
    " \n",
    " x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    " W = tf.Variable(tf.zeros([784, 10]))\n",
    " b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "\n",
    " y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    " y_ = tf.placeholder(tf.float32, [None, 10])\n",
    " cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    " \n",
    "\n",
    "\n",
    "\n",
    " learning_rate = 0.05\n",
    " train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    " sess = tf.Session()\n",
    " tf.global_variables_initializer().run()\n",
    " for _ in range(1000):\n",
    " \tbatch_xs, batch_ys = mnist.train.next_batch(100)\n",
    " \tsess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    " correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    " accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    " print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-292b9248f01e>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./MNIST/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'matul'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-292b9248f01e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mtrain_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-292b9248f01e>\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# output of NN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-292b9248f01e>\u001b[0m in \u001b[0;36mbuild_nn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mhidden_layer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mhidden_layer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moutput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-292b9248f01e>\u001b[0m in \u001b[0;36madd_layer\u001b[0;34m(input_data, input_num, output_num, activation_function)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m#activation? output = activation_function(output) : output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mactivation_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dw_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accessing local variables before they are created.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     if (self._dw_warning_count < _PER_MODULE_WARNING_LIMIT and\n\u001b[1;32m    108\u001b[0m         name not in self._dw_deprecated_printed):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'matul'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('./MNIST', one_hot=True)\n",
    "\n",
    "#input_layer\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None,784], name='x')\n",
    "#labels\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None,10], name='y')\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "def add_layer(input_data, input_num, output_num, activation_function=None):\n",
    "\t#output = input_data * weight + bias\n",
    "\tw = tf.Variable(initial_value = tf.random_normal(shape=[input_num, output_num]))\n",
    "\tb = tf.Variable(initial_value = tf.random_normal(shape=[1, output_num]))\n",
    "\toutput = tf.add(tf.matul(input_data, w), b)\n",
    "\t#activation? output = activation_function(output) : output\n",
    "\tif activation_function:\n",
    "\t\toutput = activation_function(output)\n",
    "\treturn output\n",
    "\t\n",
    "\n",
    "def build_nn(data):\n",
    "\thidden_layer1 = add_layer(data, 784, 100, activation_function=tf.nn.sigmoid)\n",
    "\thidden_layer2 = add_layer(hidden_layer1, 100, 50, activation_function=tf.nn.sigmoid)\n",
    "\toutput_layer = add_layer(hidden_layer2, 50, 10)\n",
    "\treturn output_layer\n",
    "\n",
    "def train_nn(data):\n",
    "\t# output of NN\n",
    "\toutput = build_nn(data)\n",
    "\n",
    "\tloss = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output)\n",
    "\toptimizer = tf.train.GradientDescentOptimizer(learning_rate=1).minimize(loss)\n",
    "\n",
    "\n",
    "\twith tf.Session() as sess:\n",
    "\t\tsess.run(tf.global_variables_initializer())\n",
    "\t\tfor _ in range(50):\n",
    "\t\t\tepoch_cost = 0\n",
    "\t\t\tfor _ in range(int(mnist.train.num_wxamples / batch_size)):\n",
    "\t\t\t\tx_data, y_data = mnist.train.next_batch(batch_size)\n",
    "\t\t\t\tcost, _ = sess.run([loss, optimizer], feed_dict={x: x_data, y: y_data})\n",
    "\t\t\t\tepoch_cost += cost\n",
    "\t\t\tprint('Epoch', i, ': ', epoch_cost)\n",
    "\n",
    "\n",
    "train_nn(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-32406192f58c>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-32406192f58c>:35: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch 0 :  96.40404069423676\n",
      "Epoch 1 :  48.2375248670578\n",
      "Epoch 2 :  38.19425868988037\n",
      "Epoch 3 :  33.068891763687134\n",
      "Epoch 4 :  29.779543787240982\n",
      "Epoch 5 :  27.41325905919075\n",
      "Epoch 6 :  25.566686928272247\n",
      "Epoch 7 :  24.134378403425217\n",
      "Epoch 8 :  22.935086101293564\n",
      "Epoch 9 :  21.866574108600616\n",
      "Epoch 10 :  20.972550481557846\n",
      "Epoch 11 :  20.188227951526642\n",
      "Epoch 12 :  19.488261610269547\n",
      "Epoch 13 :  18.80759361386299\n",
      "Epoch 14 :  18.267844915390015\n",
      "Epoch 15 :  17.720670610666275\n",
      "Epoch 16 :  17.240690499544144\n",
      "Epoch 17 :  16.76515792310238\n",
      "Epoch 18 :  16.3525477796793\n",
      "Epoch 19 :  15.948302313685417\n",
      "Epoch 20 :  15.58385719358921\n",
      "Epoch 21 :  15.260212168097496\n",
      "Epoch 22 :  14.899977758526802\n",
      "Epoch 23 :  14.608863070607185\n",
      "Epoch 24 :  14.30908551812172\n",
      "Epoch 25 :  14.054111734032631\n",
      "Epoch 26 :  13.79406002163887\n",
      "Epoch 27 :  13.519230127334595\n",
      "Epoch 28 :  13.283317267894745\n",
      "Epoch 29 :  13.043060645461082\n",
      "Epoch 30 :  12.841736242175102\n",
      "Epoch 31 :  12.609840884804726\n",
      "Epoch 32 :  12.421912208199501\n",
      "Epoch 33 :  12.215822696685791\n",
      "Epoch 34 :  12.038092762231827\n",
      "Epoch 35 :  11.849869012832642\n",
      "Epoch 36 :  11.67348226904869\n",
      "Epoch 37 :  11.514404386281967\n",
      "Epoch 38 :  11.33833034336567\n",
      "Epoch 39 :  11.18427175283432\n",
      "Epoch 40 :  11.021166861057281\n",
      "Epoch 41 :  10.881200149655342\n",
      "Epoch 42 :  10.734985455870628\n",
      "Epoch 43 :  10.594377994537354\n",
      "Epoch 44 :  10.453529819846153\n",
      "Epoch 45 :  10.323534101247787\n",
      "Epoch 46 :  10.20036207139492\n",
      "Epoch 47 :  10.083197131752968\n",
      "Epoch 48 :  9.961227491497993\n",
      "Epoch 49 :  9.82646258175373\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'input' has DataType bool not in list of allowed values: float32, float64, int32, uint8, int16, int8, complex64, int64, qint8, quint8, qint32, bfloat16, uint16, complex128, float16, uint32, uint64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-32406192f58c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mtrain_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-32406192f58c>\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     46\u001b[0m                                 \u001b[0mepoch_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_mean_v1\u001b[0;34m(input_tensor, axis, keepdims, name, reduction_indices, keep_dims)\u001b[0m\n\u001b[1;32m   1704\u001b[0m   keepdims = deprecation.deprecated_argument_lookup(\"keepdims\", keepdims,\n\u001b[1;32m   1705\u001b[0m                                                     \"keep_dims\", keep_dims)\n\u001b[0;32m-> 1706\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_mean\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   1762\u001b[0m       gen_math_ops.mean(\n\u001b[1;32m   1763\u001b[0m           \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m           name=name))\n\u001b[0m\u001b[1;32m   1765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m   6178\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   6179\u001b[0m         \u001b[0;34m\"Mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6180\u001b[0;31m                 name=name)\n\u001b[0m\u001b[1;32m   6181\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6182\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    624\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[1;32m    625\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m                                        param_name=input_name)\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[0;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0;34m\"allowed values: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[0;32m---> 60\u001b[0;31m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Value passed to parameter 'input' has DataType bool not in list of allowed values: float32, float64, int32, uint8, int16, int8, complex64, int64, qint8, quint8, qint32, bfloat16, uint16, complex128, float16, uint32, uint64"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('./MNIST', one_hot=True)\n",
    "\n",
    "#input_layer\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None,784], name='x')\n",
    "#labels\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None,10], name='y')\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "def add_layer(input_data, input_num, output_num, activation_function=None):\n",
    "\t#output = input_data * weight + bias\n",
    "\tw = tf.Variable(initial_value=tf.random_normal(shape=[input_num, output_num]))\n",
    "\tb = tf.Variable(initial_value=tf.random_normal(shape=[1, output_num]))\n",
    "\toutput = tf.add(tf.matmul(input_data, w), b)\n",
    "\t#activation? output = activation_function(output) : output\n",
    "\tif activation_function:\n",
    "\t\toutput = activation_function(output)\n",
    "\treturn output\n",
    "\t\n",
    "\n",
    "def build_nn(data):\n",
    "\thidden_layer1 = add_layer(data, 784, 100, activation_function=tf.nn.sigmoid)\n",
    "\thidden_layer2 = add_layer(hidden_layer1, 100, 50, activation_function=tf.nn.sigmoid)\n",
    "\toutput_layer = add_layer(hidden_layer2, 50, 10)\n",
    "\treturn output_layer\n",
    "\n",
    "def train_nn(data):\n",
    "\t# output of NN\n",
    "\toutput = build_nn(data)\n",
    "\n",
    "\tloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output))\n",
    "\toptimizer = tf.train.GradientDescentOptimizer(learning_rate=1).minimize(loss)\n",
    "\n",
    "\n",
    "\twith tf.Session() as sess:\n",
    "\t\tsess.run(tf.global_variables_initializer())\n",
    "\t\tfor i in range(50):\n",
    "\t\t\tepoch_cost = 0\n",
    "\t\t\tfor _ in range(int(mnist.train.num_examples / batch_size)):\n",
    "\t\t\t\tx_data, y_data = mnist.train.next_batch(batch_size)\n",
    "\t\t\t\tcost, _ = sess.run([loss, optimizer], feed_dict={x: x_data, y: y_data})\n",
    "\t\t\t\tepoch_cost += cost\n",
    "\t\t\tprint('Epoch', i, ': ', epoch_cost)\n",
    "\t\taccuracy = tf.reduce_mean(tf.equal(tf.argmax(y, 1), tf.argmax(output, 1)))\n",
    "\t\tacc = sess.run(accuracy, feed_dict={x: mnist.test.images, y:mnist.test.labels})\n",
    "\t\tprint(acc)\n",
    "\n",
    "\n",
    "train_nn(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Epoch 0 :  98.06475150585175\n",
      "Epoch 1 :  50.5432990193367\n",
      "Epoch 2 :  41.005087435245514\n",
      "Epoch 3 :  35.626270174980164\n",
      "Epoch 4 :  32.0650110244751\n",
      "Epoch 5 :  29.45045605301857\n",
      "Epoch 6 :  27.397424817085266\n",
      "Epoch 7 :  25.77886837720871\n",
      "Epoch 8 :  24.41167649626732\n",
      "Epoch 9 :  23.243982434272766\n",
      "Epoch 10 :  22.223884254693985\n",
      "Epoch 11 :  21.357547730207443\n",
      "Epoch 12 :  20.560326159000397\n",
      "Epoch 13 :  19.878439396619797\n",
      "Epoch 14 :  19.26376783847809\n",
      "Epoch 15 :  18.687265425920486\n",
      "Epoch 16 :  18.163066685199738\n",
      "Epoch 17 :  17.66855499148369\n",
      "Epoch 18 :  17.225654661655426\n",
      "Epoch 19 :  16.806100264191628\n",
      "Epoch 20 :  16.43321041762829\n",
      "Epoch 21 :  16.08352129161358\n",
      "Epoch 22 :  15.75071069598198\n",
      "Epoch 23 :  15.42913706600666\n",
      "Epoch 24 :  15.120894521474838\n",
      "Epoch 25 :  14.827313467860222\n",
      "Epoch 26 :  14.586428806185722\n",
      "Epoch 27 :  14.313869312405586\n",
      "Epoch 28 :  14.084264934062958\n",
      "Epoch 29 :  13.839930430054665\n",
      "Epoch 30 :  13.617720693349838\n",
      "Epoch 31 :  13.401629343628883\n",
      "Epoch 32 :  13.189913272857666\n",
      "Epoch 33 :  12.998442769050598\n",
      "Epoch 34 :  12.816014587879181\n",
      "Epoch 35 :  12.622123077511787\n",
      "Epoch 36 :  12.444811701774597\n",
      "Epoch 37 :  12.267277374863625\n",
      "Epoch 38 :  12.11037366092205\n",
      "Epoch 39 :  11.92981082201004\n",
      "Epoch 40 :  11.779417008161545\n",
      "Epoch 41 :  11.640798047184944\n",
      "Epoch 42 :  11.475484549999237\n",
      "Epoch 43 :  11.329922303557396\n",
      "Epoch 44 :  11.19733813405037\n",
      "Epoch 45 :  11.052842631936073\n",
      "Epoch 46 :  10.922329977154732\n",
      "Epoch 47 :  10.777287915349007\n",
      "Epoch 48 :  10.674185931682587\n",
      "Epoch 49 :  10.538464531302452\n",
      "0.9245\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('./MNIST', one_hot=True)\n",
    "\n",
    "#input_layer\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None,784], name='x')\n",
    "#labels\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None,10], name='y')\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "def add_layer(input_data, input_num, output_num, activation_function=None):\n",
    "\t#output = input_data * weight + bias\n",
    "\tw = tf.Variable(initial_value=tf.random_normal(shape=[input_num, output_num]))\n",
    "\tb = tf.Variable(initial_value=tf.random_normal(shape=[1, output_num]))\n",
    "\toutput = tf.add(tf.matmul(input_data, w), b)\n",
    "\t#activation? output = activation_function(output) : output\n",
    "\tif activation_function:\n",
    "\t\toutput = activation_function(output)\n",
    "\treturn output\n",
    "\t\n",
    "\n",
    "def build_nn(data):\n",
    "\thidden_layer1 = add_layer(data, 784, 100, activation_function=tf.nn.sigmoid)\n",
    "\thidden_layer2 = add_layer(hidden_layer1, 100, 50, activation_function=tf.nn.sigmoid)\n",
    "\toutput_layer = add_layer(hidden_layer2, 50, 10)\n",
    "\treturn output_layer\n",
    "\n",
    "def train_nn(data):\n",
    "\t# output of NN\n",
    "\toutput = build_nn(data)\n",
    "\n",
    "\tloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output))\n",
    "\toptimizer = tf.train.GradientDescentOptimizer(learning_rate=1).minimize(loss)\n",
    "\n",
    "\n",
    "\twith tf.Session() as sess:\n",
    "\t\tsess.run(tf.global_variables_initializer())\n",
    "\t\tfor i in range(50):\n",
    "\t\t\tepoch_cost = 0\n",
    "\t\t\tfor _ in range(int(mnist.train.num_examples / batch_size)):\n",
    "\t\t\t\tx_data, y_data = mnist.train.next_batch(batch_size)\n",
    "\t\t\t\tcost, _ = sess.run([loss, optimizer], feed_dict={x: x_data, y: y_data})\n",
    "\t\t\t\tepoch_cost += cost\n",
    "\t\t\tprint('Epoch', i, ': ', epoch_cost)\n",
    "\t\taccuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y, 1), tf.argmax(output, 1)), tf.float32)) \n",
    "\t\tacc = sess.run(accuracy, feed_dict={x: mnist.test.images, y:mnist.test.labels})\n",
    "\t\tprint(acc)\n",
    "\n",
    "\n",
    "train_nn(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-fb805d36e99e>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "---\n",
      "3\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fb805d36e99e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# 印出來看看\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mfirst_train_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_train_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "# 讀入 MNIST\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "# 檢視結構\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(\"---\")\n",
    "\n",
    "# 檢視一個觀測值\n",
    "#print(x_train[1, :])\n",
    "print(np.argmax(y_train[1, :])) # 第一張訓練圖片的真實答案\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# 讀入 MNIST\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_train = mnist.train.images\n",
    "\n",
    "# 印出來看看\n",
    "first_train_img = np.reshape(x_train[1, :], (28, 28))\n",
    "plt.matshow(first_train_img, cmap = plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "---\n",
      "3\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 讀入 MNIST\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "# 檢視結構\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(\"---\")\n",
    "\n",
    "# 檢視一個觀測值\n",
    "#print(x_train[1, :])\n",
    "print(np.argmax(y_train[1, :])) # 第一張訓練圖片的真實答案\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# 讀入 MNIST\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_train = mnist.train.images\n",
    "\n",
    "# 印出來看看\n",
    "first_train_img = np.reshape(x_train[1, :], (28, 28))\n",
    "plt.matshow(first_train_img, cmap = plt.get_cmap('gray'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-1-6d89a3ec8a79>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-6d89a3ec8a79>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    x = tf.placeholder(tf.float32, [None, 784])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "\n",
    "import tensorflow as tf \n",
    " \n",
    " x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    " W = tf.Variable(tf.zeros([784, 10]))\n",
    " b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "\n",
    " y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    " y_ = tf.placeholder(tf.float32, [None, 10])\n",
    " cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    " learning_rate = 0.05\n",
    " train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    " sess = tf.Session()\n",
    " tf.global_variables_initializer().run()\n",
    " for _ in range(1000):\n",
    " \tbatch_xs, batch_ys = mnist.train.next_batch(100)\n",
    " \tsess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    " correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    " accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    " print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
